---
references:
- id: alaboZafei2014a
  abstract: >-
    In this paper we provide the ﬁrst, to the best of our knowledge, Bayesian
    formulation of one of the most successful and well-studied statistical
    models of shape and texture, i.e. Active Appearance Models (AAMs). To this
    end, we use a simple probabilistic model for texture generation assuming
    both Gaussian noise and a Gaussian prior over a latent texture space. We
    retrieve the shape parameters by formulating a novel cost function obtained
    by marginalizing out the latent texture space. This results in a fast
    implementation when compared to other simultaneous algorithms for ﬁtting
    AAMs, mainly due to the removal of the calculation of texture parameters. We
    demonstrate that, contrary to what is believed regarding the performance of
    AAMs in generic ﬁtting scenarios, optimization of the proposed cost function
    produces results that outperform discriminatively trained state-of-the-art
    methods in the problem of facial alignment “in the wild”.
  accessed:
    - year: 2022
      month: 5
      day: 15
  author:
    - family: Alabort-i-Medina
      given: Joan
    - family: Zafeiriou
      given: Stefanos
  citation-key: alaboZafei2014a
  container-title: 2014 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2014.439
  event: 2014 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
  event-place: Columbus, OH, USA
  ISBN: 978-1-4799-5118-5
  issued:
    - year: 2014
      month: 6
  language: en
  page: 3438-3445
  publisher: IEEE
  publisher-place: Columbus, OH, USA
  source: DOI.org (Crossref)
  title: Bayesian Active Appearance Models
  type: paper-conference
  URL: https://ieeexplore.ieee.org/document/6909835

- id: alaboZafei2016a
  abstract: >-
    Active Appearance Models (AAMs) are one of the most popular and
    well-established techniques for modeling deformable objects in computer
    vision. In this paper, we study the problem of fitting AAMs using
    Compositional Gradient Descent (CGD) algorithms. We present a unified and
    complete view of these algorithms and classify them with respect to three
    main characteristics: i) cost function; ii) type of composition; and iii)
    optimization method. Furthermore, we extend the previous view by: a)
    proposing a novel Bayesian cost function that can be interpreted as a
    general probabilistic formulation of the well-known project-out loss; b)
    introducing two new types of composition, asymmetric and bidirectional, that
    combine the gradients of both image and appearance model to derive better
    conver- gent and more robust CGD algorithms; and c) providing new valuable
    insights into existent CGD algorithms by reinterpreting them as direct
    applications of the Schur complement and the Wiberg method. Finally, in
    order to encourage open research and facilitate future comparisons with our
    work, we make the implementa- tion of the algorithms studied in this paper
    publicly available as part of the Menpo Project.
  accessed:
    - year: 2022
      month: 5
      day: 16
  author:
    - family: Alabort-i-Medina
      given: Joan
    - family: Zafeiriou
      given: Stefanos
  citation-key: alaboZafei2016a
  container-title: arXiv:1601.00199 [cs]
  issued:
    - year: 2016
      month: 1
      day: 2
  note: '# of Pages: 39'
  source: arXiv.org
  title: A Unified Framework for Compositional Fitting of Active Appearance Models
  type: article-journal
  URL: http://arxiv.org/abs/1601.00199

- id: almad2018a
  abstract: >-
    Face detection is a crucial task in multistage computer vision systems. This
    paper establishes an effort to summarize the face detection algorithms
    published in the field. Survey and review papers are always very helpful for
    both new and experienced researchers equally. Such surveys enable new
    researchers to dive deeply into the field and grasp gist of algorithms,
    while experienced researchers can easily track advancements in a specific
    area. Therefore, survey papers have an important role of contribution in the
    field. This article points out and summarizes the algorithms in which
    feature extraction techniques and back end machine learning classifiers have
    been investigated. The algorithms are compared quantitatively and
    qualitatively.
  author:
    - family: Almadhor
      given: Ahmad
  citation-key: almad2018a
  container-title: >-
    2018 18th International Conference on Control, Automation and Systems
    (ICCAS)
  event: >-
    2018 18th International Conference on Control, Automation and Systems
    (ICCAS)
  issued:
    - year: 2018
      month: 10
  page: 1642-1647
  source: IEEE Xplore
  title: 'Comparative Analysis of Face Detection Algorithms: Novice to Novel'
  title-short: Comparative Analysis of Face Detection Algorithms
  type: paper-conference

- id: antonAlaboEtAl2015a
  abstract: >-
    Lucas-Kanade and active appearance models are among the most commonly used
    methods for image alignment and facial fitting, respectively. They both
    utilize nonlinear gradient descent, which is usually applied on intensity
    values. In this paper, we propose the employment of highly descriptive,
    densely sampled image features for both problems. We show that the strategy
    of warping the multichannel dense feature image at each iteration is more
    beneficial than extracting features after warping the intensity image at
    each iteration. Motivated by this observation, we demonstrate robust and
    accurate alignment and fitting performance using a variety of powerful
    feature descriptors. Especially with the employment of histograms of
    oriented gradient and scale-invariant feature transform features, our method
    significantly outperforms the current state-of-the-art results on
    in-the-wild databases.
  author:
    - family: Antonakos
      given: Epameinondas
    - family: Alabort-i-Medina
      given: Joan
    - family: Tzimiropoulos
      given: Georgios
    - family: Zafeiriou
      given: Stefanos P.
  citation-key: antonAlaboEtAl2015a
  container-title: IEEE Transactions on Image Processing
  DOI: 10.1109/TIP.2015.2431445
  ISSN: 1941-0042
  issue: '9'
  issued:
    - year: 2015
      month: 9
  page: 2617-2632
  source: IEEE Xplore
  title: Feature-Based Lucas–Kanade and Active Appearance Models
  type: article-journal
  volume: '24'

- id: asthaZafeiEtAl2013a
  accessed:
    - year: 2021
      month: 11
      day: 23
  author:
    - family: Asthana
      given: Akshay
    - family: Zafeiriou
      given: Stefanos
    - family: Cheng
      given: Shiyang
    - family: Pantic
      given: Maja
  citation-key: asthaZafeiEtAl2013a
  event: >-
    Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition
  issued:
    - year: 2013
  page: 3444-3451
  source: openaccess.thecvf.com
  title: Robust Discriminative Response Map Fitting with Constrained Local Models
  type: paper-conference
  URL: >-
    https://openaccess.thecvf.com/content_cvpr_2013/html/Asthana_Robust_Discriminative_Response_2013_CVPR_paper.html

- id: baltrRobinEtAl2013a
  abstract: >-
    Facial feature detection algorithms have seen great progress over the recent
    years. However, they still struggle in poor lighting conditions and in the
    presence of extreme pose or occlusions. We present the Constrained Local
    Neural Field model for facial landmark detection. Our model includes two
    main novelties. First, we introduce a probabilistic patch expert (landmark
    detector) that can learn non-linear and spatial relationships between the
    input pixels and the probability of a landmark being aligned. Secondly, our
    model is optimised using a novel Non-uniform Regularised Landmark Mean-Shift
    optimisation technique, which takes into account the reliabilities of each
    patch expert. We demonstrate the beneﬁt of our approach on a number of
    publicly available datasets over other state-of-the-art approaches when
    performing landmark detection in unseen lighting conditions and in the wild.
  accessed:
    - year: 2022
      month: 5
      day: 4
  author:
    - family: Baltrusaitis
      given: Tadas
    - family: Robinson
      given: Peter
    - family: Morency
      given: Louis-Philippe
  citation-key: baltrRobinEtAl2013a
  container-title: 2013 IEEE International Conference on Computer Vision Workshops
  DOI: 10.1109/ICCVW.2013.54
  event: 2013 IEEE International Conference on Computer Vision Workshops (ICCVW)
  event-place: Sydney, Australia
  ISBN: 978-1-4799-3022-7
  issued:
    - year: 2013
      month: 12
  language: en
  note: 'Implementation: https://github.com/TadasBaltrusaitis/OpenFace'
  page: 354-361
  publisher: IEEE
  publisher-place: Sydney, Australia
  source: DOI.org (Crossref)
  title: >-
    Constrained Local Neural Fields for Robust Facial Landmark Detection in the
    Wild
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/6755919/

- id: baltrZadehEtAl2018a
  abstract: >-
    Over the past few years, there has been an increased interest in automatic
    facial behavior analysis and understanding. We present OpenFace 2.0 — a tool
    intended for computer vision and machine learning researchers, affective
    computing community and people interested in building interactive
    applications based on facial behavior analysis. OpenFace 2.0 is an extension
    of OpenFace toolkit (created by Baltrusˇaitis et al. [11]) and is capable of
    more accurate facial landmark detection, head pose estimation, facial action
    unit recognition, and eye-gaze estimation. The computer vision algorithms
    which represent the core of OpenFace 2.0 demonstrate state-of-theart results
    in all of the above mentioned tasks. Furthermore, our tool is capable of
    real-time performance and is able to run from a simple webcam without any
    specialist hardware. Finally, unlike a lot of modern approaches or toolkits,
    OpenFace 2.0 source code for training models and running them is freely
    available for research purposes.
  accessed:
    - year: 2022
      month: 5
      day: 8
  author:
    - family: Baltrusaitis
      given: Tadas
    - family: Zadeh
      given: Amir
    - family: Lim
      given: Yao Chong
    - family: Morency
      given: Louis-Philippe
  citation-key: baltrZadehEtAl2018a
  container-title: >-
    2018 13th IEEE International Conference on Automatic Face & Gesture
    Recognition (FG 2018)
  DOI: 10.1109/FG.2018.00019
  event: >-
    2018 13th IEEE International Conference on Automatic Face & Gesture
    Recognition (FG 2018)
  event-place: Xi'an
  ISBN: 978-1-5386-2335-0
  issued:
    - year: 2018
      month: 5
  language: en
  page: 59-66
  publisher: IEEE
  publisher-place: Xi'an
  source: DOI.org (Crossref)
  title: 'OpenFace 2.0: Facial Behavior Analysis Toolkit'
  title-short: OpenFace 2.0
  type: paper-conference
  URL: https://ieeexplore.ieee.org/document/8373812/

- id: bulatTzimi2020a
  abstract: >-
    Our goal is to design architectures that retain the groundbreaking
    performance of Convolutional Neural Networks (CNNs) for landmark
    localization and at the same time are lightweight, compact and suitable for
    applications with limited computational resources. To this end, we make the
    following contributions: (a) we are the first to study the effect of neural
    network binarization on localization tasks, namely human pose estimation and
    face alignment. We exhaustively evaluate various design choices, identify
    performance bottlenecks, and more importantly propose multiple orthogonal
    ways to boost performance. (b) Based on our analysis, we propose a novel
    hierarchical, parallel and multi-scale residual architecture that yields
    large performance improvement over the standard bottleneck block while
    having the same number of parameters, thus bridging the gap between the
    original network and its binarized counterpart. (c) We perform a large
    number of ablation studies that shed light on the properties and the
    performance of the proposed block. (d) We present results for experiments on
    the most challenging datasets for human pose estimation and face alignment,
    reporting in many cases state-of-the-art performance. (e) We further provide
    additional results for the problem of facial part segmentation. Code can be
    downloaded from https://www.adrianbulat.com/binary-cnn-landmarks.
  author:
    - family: Bulat
      given: Adrian
    - family: Tzimiropoulos
      given: Georgios
  citation-key: bulatTzimi2020a
  container-title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  DOI: 10.1109/TPAMI.2018.2866051
  ISSN: 1939-3539
  issue: '2'
  issued:
    - year: 2020
      month: 2
  note: 'Implementation: https://www.adrianbulat.com/binary-cnn-landmarks'
  page: 343-356
  source: IEEE Xplore
  title: Hierarchical Binary CNNs for Landmark Localization with Limited Resources
  type: article-journal
  volume: '42'

- id: buolaGebru2018a
  abstract: >-
    Recent studies demonstrate that machine learning algorithms can discriminate
    based on classes like race and gender. In this work, we present an approach
    to evaluate bias present in automated facial analysis algorithms and
    datasets with respect to phenotypic subgroups. Using the dermatologist 
    approved Fitzpatrick Skin Type classification system, we characterize the
    gender and skin type distribution of two facial analysis benchmarks, IJB-A
    and Adience. We find that these datasets are overwhelmingly composed of
    lighter-skinned subjects (79.6% for IJB-A and 86.2% for Adience) and
    introduce a new facial analysis dataset which is balanced by gender and skin
    type. We evaluate 3 commercial gender classification systems using our
    dataset and show that darker-skinned females are the most misclassified
    group (with error rates of up to 34.7%). The maximum error rate for
    lighter-skinned males is 0.8%. The substantial disparities in the accuracy
    of classifying darker females, lighter females, darker males, and lighter
    males in gender classification systems require urgent attention if
    commercial companies are to build genuinely fair, transparent and
    accountable facial analysis algorithms.
  accessed:
    - year: 2021
      month: 11
      day: 24
  author:
    - family: Buolamwini
      given: Joy
    - family: Gebru
      given: Timnit
  citation-key: buolaGebru2018a
  container-title: >-
    Proceedings of the 1st Conference on Fairness, Accountability and
    Transparency
  event: Conference on Fairness, Accountability and Transparency
  ISSN: 2640-3498
  issued:
    - year: 2018
      month: 1
      day: 21
  language: en
  page: 77-91
  publisher: PMLR
  source: proceedings.mlr.press
  title: >-
    Gender Shades: Intersectional Accuracy Disparities in Commercial Gender
    Classification
  title-short: Gender Shades
  type: paper-conference
  URL: https://proceedings.mlr.press/v81/buolamwini18a.html

- id: cooteEdwarEtAl2001a
  abstract: >-
    We describe a new method of matching statistical models of appearance to
    images. A set of model parameters control modes of shape and gray-level
    variation learned from a training set. We construct an efficient iterative
    matching algorithm by learning the relationship between perturbations in the
    model parameters and the induced image errors.
  author:
    - family: Cootes
      given: T.F.
    - family: Edwards
      given: G.J.
    - family: Taylor
      given: C.J.
  citation-key: cooteEdwarEtAl2001a
  container-title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  DOI: 10.1109/34.927467
  ISSN: 1939-3539
  issue: '6'
  issued:
    - year: 2001
      month: 6
  page: 681-685
  source: IEEE Xplore
  title: Active appearance models
  type: article-journal
  volume: '23'

- id: cristCoote2004b
  abstract: >-
    We consider the problem of robustly and accurately locating facial features.
    The relative positions of different feature points are represented using a
    statistical shape model. We construct an individual detector for each
    feature point, which is used to generate a feature response image. The
    quality of a given hypothesised shape can be evaluated quickly by combining
    values from each response image. We use global search to predict the
    approximate position of the face, and then refine the hypothesis using
    non-linear optimisation. The result is an algorithm capable of robustly and
    accurately matching a face model to new images, which we refer to as shape
    optimised search (SOS). We describe SOS in detail and compare the
    performance of the algorithm when three different classes of feature
    detectors are used. We demonstrate that the approach is capable of
    outperforming the well known active appearance model method.
  author:
    - family: Cristinacce
      given: D.
    - family: Cootes
      given: T.F.
  citation-key: cristCoote2004b
  container-title: >-
    Sixth IEEE International Conference on Automatic Face and Gesture
    Recognition, 2004. Proceedings.
  DOI: 10.1109/AFGR.2004.1301561
  event: >-
    Sixth IEEE International Conference on Automatic Face and Gesture
    Recognition, 2004. Proceedings.
  issued:
    - year: 2004
      month: 5
  page: 375-380
  source: IEEE Xplore
  title: A comparison of shape constrained facial feature detectors
  type: paper-conference

- id: cristCoote2006a
  accessed:
    - year: 2022
      month: 4
      day: 29
  author:
    - family: Cristinacce
      given: D.
    - family: Cootes
      given: T. F.
  citation-key: cristCoote2006a
  container-title: Procedings of the British Machine Vision Conference 2006
  DOI: 10.5244/C.20.95
  event: British Machine Vision Conference 2006
  event-place: Edinburgh
  ISBN: 978-1-901725-32-2
  issued:
    - year: 2006
  language: en
  page: 95.1-95.10
  publisher: British Machine Vision Association
  publisher-place: Edinburgh
  source: DOI.org (Crossref)
  title: Feature Detection and Tracking with Constrained Local Models
  type: paper-conference
  URL: http://www.bmva.org/bmvc/2006/papers/024.html

- id: dalalTrigg2005a
  abstract: >-
    We study the question of feature sets for robust visual object recognition;
    adopting linear SVM based human detection as a test case. After reviewing
    existing edge and gradient based descriptors, we show experimentally that
    grids of histograms of oriented gradient (HOG) descriptors significantly
    outperform existing feature sets for human detection. We study the influence
    of each stage of the computation on performance, concluding that fine-scale
    gradients, fine orientation binning, relatively coarse spatial binning, and
    high-quality local contrast normalization in overlapping descriptor blocks
    are all important for good results. The new approach gives near-perfect
    separation on the original MIT pedestrian database, so we introduce a more
    challenging dataset containing over 1800 annotated human images with a large
    range of pose variations and backgrounds.
  author:
    - family: Dalal
      given: N.
    - family: Triggs
      given: B.
  citation-key: dalalTrigg2005a
  container-title: >-
    2005 IEEE Computer Society Conference on Computer Vision and Pattern
    Recognition (CVPR'05)
  DOI: 10.1109/CVPR.2005.177
  event: >-
    2005 IEEE Computer Society Conference on Computer Vision and Pattern
    Recognition (CVPR'05)
  ISSN: 1063-6919
  issued:
    - year: 2005
      month: 6
  page: 886-893 vol. 1
  source: IEEE Xplore
  title: Histograms of oriented gradients for human detection
  type: paper-conference
  volume: '1'

- id: dantoGallEtAl2012a
  abstract: >-
    Although facial feature detection from 2D images is a well-studied field,
    there is a lack of real-time methods that estimate feature points even on
    low quality images. Here we propose conditional regression forest for this
    task. While regression forest learn the relations between facial image
    patches and the location of feature points from the entire set of faces,
    conditional regression forest learn the relations conditional to global face
    properties. In our experiments, we use the head pose as a global property
    and demonstrate that conditional regression forests outperform regression
    forests for facial feature detection. We have evaluated the method on the
    challenging Labeled Faces in the Wild [20] database where close-to-human
    accuracy is achieved while processing images in real-time.
  author:
    - family: Dantone
      given: Matthias
    - family: Gall
      given: Juergen
    - family: Fanelli
      given: Gabriele
    - family: Van Gool
      given: Luc
  citation-key: dantoGallEtAl2012a
  container-title: 2012 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2012.6247976
  event: 2012 IEEE Conference on Computer Vision and Pattern Recognition
  ISSN: 1063-6919
  issued:
    - year: 2012
      month: 6
  page: 2578-2585
  source: IEEE Xplore
  title: Real-time facial feature detection using conditional regression forests
  type: paper-conference

- id: dengRoussEtAl2019a
  abstract: >-
    In this article, we present the Menpo 2D and Menpo 3D benchmarks, two new
    datasets for multi-pose 2D and 3D facial landmark localisation and tracking.
    In contrast to the previous benchmarks such as 300W and 300VW, the proposed
    benchmarks contain facial images in both semi-frontal and profile pose. We
    introduce an elaborate semi-automatic methodology for providing high-quality
    annotations for both the Menpo 2D and Menpo 3D benchmarks. In Menpo 2D
    benchmark, different visible landmark configurations are designed for
    semi-frontal and profile faces, thus making the 2D face alignment full-pose.
    In Menpo 3D benchmark, a united landmark configuration is designed for both
    semi-frontal and profile faces based on the correspondence with a 3D face
    model, thus making face alignment not only full-pose but also corresponding
    to the real-world 3D space. Based on the considerable number of annotated
    images, we organised Menpo 2D Challenge and Menpo 3D Challenge for face
    alignment under large pose variations in conjunction with CVPR 2017 and ICCV
    2017, respectively. The results of these challenges demonstrate that recent
    deep learning architectures, when trained with the abundant data, lead to
    excellent results. We also provide a very simple, yet effective solution,
    named Cascade Multi-view Hourglass Model, to 2D and 3D face alignment. In
    our method, we take advantage of all 2D and 3D facial landmark annotations
    in a joint way. We not only capitalise on the correspondences between the
    semi-frontal and profile 2D facial landmarks but also employ joint
    supervision from both 2D and 3D facial landmarks. Finally, we discuss future
    directions on the topic of face alignment.
  accessed:
    - year: 2022
      month: 4
      day: 30
  author:
    - family: Deng
      given: Jiankang
    - family: Roussos
      given: Anastasios
    - family: Chrysos
      given: Grigorios
    - family: Ververas
      given: Evangelos
    - family: Kotsia
      given: Irene
    - family: Shen
      given: Jie
    - family: Zafeiriou
      given: Stefanos
  citation-key: dengRoussEtAl2019a
  container-title: International Journal of Computer Vision
  container-title-short: Int J Comput Vis
  DOI: 10.1007/s11263-018-1134-y
  ISSN: 1573-1405
  issue: '6'
  issued:
    - year: 2019
      month: 6
      day: 1
  language: en
  page: 599-624
  source: Springer Link
  title: >-
    The Menpo Benchmark for Multi-pose 2D and 3D Facial Landmark Localisation
    and Tracking
  type: article-journal
  URL: https://doi.org/10.1007/s11263-018-1134-y
  volume: '127'

- id: edwarTayloEtAl1998a
  abstract: >-
    We demonstrate a fast, robust method of interpreting face images using an
    Active Appearance Model (AAM). An AAM contains a statistical model of shape
    and grey level appearance which can generalise to almost any face. Matching
    to an image involves finding model parameters which minimise the difference
    between the image and a synthesised face. We observe that displacing each
    model parameter from the correct value induces a particular pattern in the
    residuals. In a training phase, the AAM learns a linear model of the
    correlation between parameter displacements and the induced residuals.
    During search it measures the residuals and uses this model to correct the
    current parameters, leading to a better fit. A good overall match is
    obtained in a few iterations, even from poor starting estimates. We describe
    the technique in detail and show it matching to new face images.
  author:
    - family: Edwards
      given: G.J.
    - family: Taylor
      given: C.J.
    - family: Cootes
      given: T.F.
  citation-key: edwarTayloEtAl1998a
  container-title: >-
    Proceedings Third IEEE International Conference on Automatic Face and
    Gesture Recognition
  DOI: 10.1109/AFGR.1998.670965
  event: >-
    Proceedings Third IEEE International Conference on Automatic Face and
    Gesture Recognition
  issued:
    - year: 1998
      month: 4
  page: 300-305
  source: IEEE Xplore
  title: Interpreting face images using active appearance models
  type: paper-conference

- id: everiEslamEtAl2015a
  abstract: "The Pascal Visual Object Classes (VOC) challenge consists of two components: (i)\_a publicly available dataset of images together with ground truth annotation and standardised evaluation software; and (ii)\_an annual competition and workshop. There are five challenges: classification, detection, segmentation, action classification, and person layout. In this paper we provide a review of the challenge from 2008–2012. The paper is intended for two audiences: algorithm designers, researchers who want to see what the state of the art is, as measured by performance on the VOC datasets, along with the limitations and weak points of the current generation of algorithms; and, challenge designers, who want to see what we as organisers have learnt from the process and our recommendations for the organisation of future challenges. To analyse the performance of submitted algorithms on the VOC datasets we introduce a number of novel evaluation methods: a bootstrapping method for determining whether differences in the performance of two algorithms are significant or not; a normalised average precision so that performance can be compared across classes with different proportions of positive instances; a clustering method for visualising the performance across multiple algorithms so that the hard and easy images can be identified; and the use of a joint classifier over the submitted algorithms in order to measure their complementarity and combined performance. We also analyse the community’s progress through time using the methods of Hoiem et al. (Proceedings of European Conference on Computer Vision, 2012) to identify the types of occurring errors. We conclude the paper with an appraisal of the aspects of the challenge that worked well, and those that could be improved in future challenges."
  accessed:
    - year: 2021
      month: 11
      day: 23
  author:
    - family: Everingham
      given: Mark
    - family: Eslami
      given: S. M. Ali
    - family: Van Gool
      given: Luc
    - family: Williams
      given: Christopher K. I.
    - family: Winn
      given: John
    - family: Zisserman
      given: Andrew
  citation-key: everiEslamEtAl2015a
  container-title: International Journal of Computer Vision
  container-title-short: Int J Comput Vis
  DOI: 10.1007/s11263-014-0733-5
  ISSN: 1573-1405
  issue: '1'
  issued:
    - year: 2015
      month: 1
      day: 1
  language: en
  page: 98-136
  source: Springer Link
  title: 'The Pascal Visual Object Classes Challenge: A Retrospective'
  title-short: The Pascal Visual Object Classes Challenge
  type: article-journal
  URL: https://doi.org/10.1007/s11263-014-0733-5
  volume: '111'

- id: forsyPonce2012a
  author:
    - family: Forsyth
      given: David
    - family: Ponce
      given: Jean
  call-number: TA1634 .F65 2012
  citation-key: forsyPonce2012a
  edition: 2nd ed
  event-place: Boston
  ISBN: 978-0-13-608592-8
  issued:
    - year: 2012
  language: en
  number-of-pages: '792'
  publisher: Pearson
  publisher-place: Boston
  source: Library of Congress ISBN
  title: 'Computer Vision: A Modern Approach'
  title-short: Computer Vision
  type: book

- id: francOnetoEtAl2021a
  abstract: >-
    In many decision-making scenarios, ranging from recreational activities to
    healthcare and policing, the use of artificial intelligence coupled with the
    ability to learn from historical data is becoming ubiquitous. This
    widespread adoption of automated systems is accompanied by the increasing
    concerns regarding their ethical implications. Fundamental rights, such as
    the ones that require the preservation of privacy, do not discriminate based
    on sensible attributes (e.g., gender, ethnicity, political/sexual
    orientation), or require one to provide an explanation for a decision, are
    daily undermined by the use of increasingly complex and less understandable
    yet more accurate learning algorithms. For this purpose, in this work, we
    work toward the development of systems able to ensure trustworthiness by
    delivering privacy, fairness, and explainability by design. In particular,
    we show that it is possible to simultaneously learn from data while
    preserving the privacy of the individuals thanks to the use of Homomorphic
    Encryption, ensuring fairness by learning a fair representation from the
    data, and ensuring explainable decisions with local and global explanations
    without compromising the accuracy of the final models. We test our approach
    on a widespread but still controversial application, namely face
    recognition, using the recent FairFace dataset to prove the validity of our
    approach.
  accessed:
    - year: 2021
      month: 11
      day: 24
  author:
    - family: Franco
      given: Danilo
    - family: Oneto
      given: Luca
    - family: Navarin
      given: Nicolò
    - family: Anguita
      given: Davide
  citation-key: francOnetoEtAl2021a
  container-title: Entropy
  DOI: 10.3390/e23081047
  issue: '8'
  issued:
    - year: 2021
      month: 8
      day: 14
  language: en
  number: '8'
  page: '1047'
  publisher: Multidisciplinary Digital Publishing Institute
  source: www.mdpi.com
  title: >-
    Toward Learning Trustworthily from Data Combining Privacy, Fairness, and
    Explainability: An Application to Face Recognition
  title-short: >-
    Toward Learning Trustworthily from Data Combining Privacy, Fairness, and
    Explainability
  type: article-journal
  URL: https://www.mdpi.com/1099-4300/23/8/1047
  volume: '23'

- id: goodfBengiEtAl2016a
  abstract: >-
    "Written by three experts in the field, Deep Learning is the only
    comprehensive book on the subject." -- Elon Musk, cochair of OpenAI;
    cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine
    learning that enables computers to learn from experience and understand the
    world in terms of a hierarchy of concepts. Because the computer gathers
    knowledge from experience, there is no need for a human computer operator to
    formally specify all the knowledge that the computer needs. The hierarchy of
    concepts allows the computer to learn complicated concepts by building them
    out of simpler ones; a graph of these hierarchies would be many layers deep.
    This book introduces a broad range of topics in deep learning. The text
    offers mathematical and conceptual background, covering relevant concepts in
    linear algebra, probability theory and information theory, numerical
    computation, and machine learning. It describes deep learning techniques
    used by practitioners in industry, including deep feedforward networks,
    regularization, optimization algorithms, convolutional networks, sequence
    modeling, and practical methodology; and it surveys such applications as
    natural language processing, speech recognition, computer vision, online
    recommendation systems, bioinformatics, and videogames. Finally, the book
    offers research perspectives, covering such theoretical topics as linear
    factor models, autoencoders, representation learning, structured
    probabilistic models, Monte Carlo methods, the partition function,
    approximate inference, and deep generative models. Deep Learning can be used
    by undergraduate or graduate students planning careers in either industry or
    research, and by software engineers who want to begin using deep learning in
    their products or platforms. A website offers supplementary material for
    both readers and instructors.
  author:
    - family: Goodfellow
      given: Ian
    - family: Bengio
      given: Yoshua
    - family: Courville
      given: Aaron
  citation-key: goodfBengiEtAl2016a
  ISBN: 978-0-262-03561-3
  issued:
    - year: 2016
  number-of-pages: '800'
  publisher: The MIT Press
  source: ACM Digital Library
  title: Deep Learning
  type: book
  URL: https://www.deeplearningbook.org/

- id: gower1975a
  abstract: >-
    SupposePi(i)(i = 1, 2, ...,m, j = 1, 2, ...,n) give the locations ofmn
    points inp-dimensional space. Collectively these may be regarded asm
    configurations, or scalings, each ofn points inp-dimensions. The problem is
    investigated of translating, rotating, reflecting and scaling them
    configurations to minimize the goodness-of-fit criterion
    Σi=1mΣi=1nΔ2(Pj(i)Gi), whereGiis the centroid of them pointsPi(i)(i = 1, 2,
    ...,m). The rotated positions of each configuration may be regarded as
    individual analyses with the centroid configuration representing a
    consensus, and this relationship with individual scaling analysis is
    discussed. A computational technique is given, the results of which can be
    summarized in analysis of variance form. The special casem = 2 corresponds
    to Classical Procrustes analysis but the choice of criterion that fits each
    configuration to the common centroid configuration avoids difficulties that
    arise when one set is fitted to the other, regarded as fixed.
  accessed:
    - year: 2022
      month: 5
      day: 10
  author:
    - family: Gower
      given: J. C.
  citation-key: gower1975a
  container-title: Psychometrika
  container-title-short: Psychometrika
  DOI: 10.1007/BF02291478
  ISSN: 1860-0980
  issue: '1'
  issued:
    - year: 1975
      month: 3
      day: 1
  language: en
  page: 33-51
  source: Springer Link
  title: Generalized procrustes analysis
  type: article-journal
  URL: https://doi.org/10.1007/BF02291478
  volume: '40'

- id: grossMatthEtAl2010a
  abstract: >-
    A close relationship exists between the advancement of face recognition
    algorithms and the availability of face databases varying factors that
    affect facial appearance in a controlled manner. The CMU PIE database has
    been very influential in advancing research in face recognition across pose
    and illumination. Despite its success the PIE database has several
    shortcomings: a limited number of subjects, single recording session and
    only few expressions captured. To address these issues we collected the CMU
    Multi-PIE database. It contains 337 subjects, imaged under 15 view points
    and 19 illumination conditions in up to four recording sessions. In this
    paper we introduce the database and describe the recording procedure. We
    furthermore present results from baseline experiments using PCA and LDA
    classifiers to highlight similarities and differences between PIE and
    Multi-PIE.
  accessed:
    - year: 2022
      month: 5
      day: 3
  author:
    - family: Gross
      given: Ralph
    - family: Matthews
      given: Iain
    - family: Cohn
      given: Jeff
    - family: Kanade
      given: Takeo
    - family: Baker
      given: Simon
  citation-key: grossMatthEtAl2010a
  container-title: >-
    Proceedings of the ... International Conference on Automatic Face and
    Gesture Recognition. International Conference on Automatic Face and Gesture
    Recognition
  container-title-short: Proc Int Conf Autom Face Gesture Recognit
  DOI: 10.1016/j.imavis.2009.08.002
  ISSN: 1541-5058
  issue: '5'
  issued:
    - year: 2010
      month: 5
      day: 1
  page: 807-813
  PMCID: PMC2873597
  PMID: '20490373'
  source: PubMed Central
  title: Multi-PIE
  type: article-journal
  URL: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2873597/
  volume: '28'

- id: ioffeForsy2001a
  abstract: >-
    Efﬁcient detection of objects in images is complicated by variations of
    object appearance due to intra-class object differences, articulation,
    lighting, occlusions, and aspect variations. To reduce the search required
    for detection, we employ the bottom-up approach where we ﬁnd candidate image
    features and associate some of them with parts of the object model. We
    represent objects as collections of local features, and would like to allow
    any of them to be absent, with only a small subset sufﬁcient for detection;
    furthermore, our model should allow efﬁcient correspondence search. We
    propose a model, Mixture of Trees, that achieves these goals. With a mixture
    of trees, we can model the individual appearances of the features,
    relationships among them, and the aspect, and handle occlusions.
    Independences captured in the model make efﬁcient inference possible. In our
    earlier work, we have shown that mixtures of trees can be used to model
    objects with a natural tree structure, in the context of human tracking. Now
    we show that a natural tree structure is not required, and use a mixture of
    trees for both frontal and view-invariant face detection. We also show that
    by modeling faces as collections of features we can establish an intrinsic
    coordinate frame for a face, and estimate the out-of-plane rotation of a
    face.
  accessed:
    - year: 2022
      month: 5
      day: 4
  author:
    - family: Ioffe
      given: S.
    - family: Forsyth
      given: D.
  citation-key: ioffeForsy2001a
  container-title: >-
    Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision
    and Pattern Recognition. CVPR 2001
  DOI: 10.1109/CVPR.2001.990953
  event: >-
    2001 IEEE Computer Society Conference on Computer Vision and Pattern
    Recognition. CVPR 2001
  event-place: Kauai, HI, USA
  ISBN: 978-0-7695-1272-3
  issued:
    - year: 2001
      month: 12
      day: 1
  language: en
  page: II-180-II-185
  publisher: IEEE Comput. Soc
  publisher-place: Kauai, HI, USA
  source: DOI.org (Crossref)
  title: Mixtures of trees for object recognition
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/990953/
  volume: '2'

- id: kabak2019a
  abstract: >-
    Face detection is the task of detecting faces on photos, videos as well as
    the streaming data such as a webcam. Face detection, which is a specific
    type of general-purpose object detection, is a key prerequisite for many
    other artificial intelligence tasks such as face verification, face tagging
    and retrieval, and face tracking. In addition to that, nowadays, face
    detection is commonly used in daily routines such as social media, and
    camera software of smartphones. As a result of this necessity, several face
    detection tools have been proposed. In this study, an experimental
    performance comparison of well-known face detection tools in terms of (1)
    accuracy, and (2) elapsed time of detection, which has become even more
    critical criteria especially when the face detection mechanism is utilized
    for a real-time system, is proposed. As a result of this experimental study,
    it is aimed that shed light on the much-concerned query “which face
    detection tool provides the best performance?”. In addition to that, this
    study succeeds in showing that convolutional neural networks achieve great
    accuracy for face detection.
  accessed:
    - year: 2021
      month: 11
      day: 24
  author:
    - family: Kabakus
      given: Abdullah Talha
  citation-key: kabak2019a
  ISSN: 2255-2863
  issued:
    - year: 2019
      month: 9
      day: 14
  language: eng
  note: 'Accepted: 2020-06-23T11:12:43Z'
  publisher: Ediciones Universidad de Salamanca (España)
  source: gredos.usal.es
  title: An Experimental Performance Comparison of Widely Used Face Detection Tools
  type: article-journal
  URL: https://gredos.usal.es/handle/10366/143310

- id: kanwiYovel2009a
  abstract: Abstract
  accessed:
    - year: 2022
      month: 4
      day: 30
  author:
    - family: Kanwisher
      given: Nancy
    - family: Yovel
      given: Galit
  citation-key: kanwiYovel2009a
  container-title: Handbook of Neuroscience for the Behavioral Sciences
  DOI: 10.1002/9780470478509.neubb002043
  ISBN: 978-0-470-47850-9
  issued:
    - year: 2009
  language: en
  note: >-
    _eprint:
    https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470478509.neubb002043
  publisher: John Wiley & Sons, Ltd
  section: '43'
  source: Wiley Online Library
  title: Face Perception
  type: chapter
  URL: https://onlinelibrary.wiley.com/doi/abs/10.1002/9780470478509.neubb002043

- id: karkkJoo2019a
  abstract: >-
    Existing public face datasets are strongly biased toward Caucasian faces,
    and other races (e.g., Latino) are significantly underrepresented. This can
    lead to inconsistent model accuracy, limit the applicability of face
    analytic systems to non-White race groups, and adversely affect research
    findings based on such skewed data. To mitigate the race bias in these
    datasets, we construct a novel face image dataset, containing 108,501
    images, with an emphasis of balanced race composition in the dataset. We
    define 7 race groups: White, Black, Indian, East Asian, Southeast Asian,
    Middle East, and Latino. Images were collected from the YFCC-100M Flickr
    dataset and labeled with race, gender, and age groups. Evaluations were
    performed on existing face attribute datasets as well as novel image
    datasets to measure generalization performance. We find that the model
    trained from our dataset is substantially more accurate on novel datasets
    and the accuracy is consistent between race and gender groups.
  accessed:
    - year: 2021
      month: 11
      day: 24
  author:
    - family: Kärkkäinen
      given: Kimmo
    - family: Joo
      given: Jungseock
  citation-key: karkkJoo2019a
  container-title: arXiv:1908.04913 [cs]
  issued:
    - year: 2019
      month: 8
      day: 13
  note: 'github: https://github.com/joojs/fairface'
  source: arXiv.org
  title: 'FairFace: Face Attribute Dataset for Balanced Race, Gender, and Age'
  title-short: FairFace
  type: article-journal
  URL: http://arxiv.org/abs/1908.04913
  version: '1'

- id: kazemSulli2014a
  abstract: >-
    This paper addresses the problem of Face Alignment for a single image. We
    show how an ensemble of regression trees can be used to estimate the face's
    landmark positions directly from a sparse subset of pixel intensities,
    achieving super-realtime performance with high quality predictions. We
    present a general framework based on gradient boosting for learning an
    ensemble of regression trees that optimizes the sum of square error loss and
    naturally handles missing or partially labelled data. We show how using
    appropriate priors exploiting the structure of image data helps with
    efficient feature selection. Different regularization strategies and its
    importance to combat overfitting are also investigated. In addition, we
    analyse the effect of the quantity of training data on the accuracy of the
    predictions and explore the effect of data augmentation using synthesized
    data.
  author:
    - family: Kazemi
      given: Vahid
    - family: Sullivan
      given: Josephine
  citation-key: kazemSulli2014a
  container-title: 2014 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2014.241
  event: 2014 IEEE Conference on Computer Vision and Pattern Recognition
  ISSN: 1063-6919
  issued:
    - year: 2014
      month: 6
  page: 1867-1874
  source: IEEE Xplore
  title: One millisecond face alignment with an ensemble of regression trees
  type: paper-conference

- id: khabaKoria2021a
  abstract: >-
    In this paper we survey and analyze modern neural-network-based facial
    landmark detection algorithms. We focus on approaches that have led to a
    significant increase in quality over the past few years on datasets with
    large pose and emotion variability, high levels of face occlusions - all of
    which are typical in real-world scenarios. We summarize the improvements
    into categories, provide quality comparison on difficult and modern
    in-the-wild datasets: 300-W, AFLW, WFLW, COFW. Additionally, we compare
    algorithm speed on CPU, GPU and Mobile devices. For completeness, we also
    briefly touch on established methods with open implementations available.
    Besides, we cover applications and vulnerabilities of the landmark detection
    algorithms. Based on which, we raise problems that as we hope will lead to
    further algorithm improvements.
  accessed:
    - year: 2022
      month: 2
      day: 11
  author:
    - family: Khabarlak
      given: Kostiantyn
    - family: Koriashkina
      given: Larysa
  citation-key: khabaKoria2021a
  container-title: arXiv:2101.10808 [cs]
  issued:
    - year: 2021
      month: 4
      day: 23
  source: arXiv.org
  title: 'Fast Facial Landmark Detection and Applications: A Survey'
  title-short: Fast Facial Landmark Detection and Applications
  type: article-journal
  URL: http://arxiv.org/abs/2101.10808

- id: king2009a
  abstract: >-
    There are many excellent toolkits which provide support for developing
    machine learning software in Python, R, Matlab, and similar environments.
    Dlib-ml is an open source library, targeted at both engineers and research
    scientists, which aims to provide a similarly rich environment for
    developing machine learning software in the C++ language. Towards this end,
    dlib-ml contains an extensible linear algebra toolkit with built in BLAS
    support. It also houses implementations of algorithms for performing
    inference in Bayesian networks and kernel-based methods for classification,
    regression, clustering, anomaly detection, and feature ranking. To enable
    easy use of these tools, the entire library has been developed with contract
    programming, which provides complete and precise documentation as well as
    powerful debugging tools.
  author:
    - family: King
      given: Davis E.
  citation-key: king2009a
  container-title: The Journal of Machine Learning Research
  container-title-short: J. Mach. Learn. Res.
  ISSN: 1532-4435
  issued:
    - year: 2009
      month: 12
      day: 1
  page: 1755–1758
  source: 12/1/2009
  title: 'Dlib-ml: A Machine Learning Toolkit'
  title-short: Dlib-ml
  type: article-journal
  volume: '10'

- id: kostiWohlhEtAl2011a
  abstract: >-
    Face alignment is a crucial step in face recognition tasks. Especially,
    using landmark localization for geometric face normalization has shown to be
    very effective, clearly improving the recognition results. However, no
    adequate databases exist that provide a sufficient number of annotated
    facial landmarks. The databases are either limited to frontal views, provide
    only a small number of annotated images or have been acquired under
    controlled conditions. Hence, we introduce a novel database overcoming these
    limitations: Annotated Facial Landmarks in the Wild (AFLW). AFLW provides a
    large-scale collection of images gathered from Flickr, exhibiting a large
    variety in face appearance (e.g., pose, expression, ethnicity, age, gender)
    as well as general imaging and environmental conditions. In total 25,993
    faces in 21,997 real-world images are annotated with up to 21 landmarks per
    image. Due to the comprehensive set of annotations AFLW is well suited to
    train and test algorithms for multi-view face detection, facial landmark
    localization and face pose estimation. Further, we offer a rich set of tools
    that ease the integration of other face databases and associated annotations
    into our joint framework.
  author:
    - family: Köstinger
      given: Martin
    - family: Wohlhart
      given: Paul
    - family: Roth
      given: Peter M.
    - family: Bischof
      given: Horst
  citation-key: kostiWohlhEtAl2011a
  container-title: >-
    2011 IEEE International Conference on Computer Vision Workshops (ICCV
    Workshops)
  DOI: 10.1109/ICCVW.2011.6130513
  event: >-
    2011 IEEE International Conference on Computer Vision Workshops (ICCV
    Workshops)
  issued:
    - year: 2011
      month: 11
  page: 2144-2151
  source: IEEE Xplore
  title: >-
    Annotated Facial Landmarks in the Wild: A large-scale, real-world database
    for facial landmark localization
  title-short: Annotated Facial Landmarks in the Wild
  type: paper-conference

- id: leBrandEtAl2012a
  abstract: >-
    We address the problem of interactive facial feature localization from a
    single image. Our goal is to obtain an accurate segmentation of facial
    features on high-resolution images under a variety of pose, expression, and
    lighting conditions. Although there has been significant work in facial
    feature localization, we are addressing a new application area, namely to
    facilitate intelligent high-quality editing of portraits, that brings
    requirements not met by existing methods. We propose an improvement to the
    Active Shape Model that allows for greater independence among the facial
    components and improves on the appearance fitting step by introducing a
    Viterbi optimization process that operates along the facial contours.
    Despite the improvements, we do not expect perfect results in all cases. We
    therefore introduce an interaction model whereby a user can efficiently
    guide the algorithm towards a precise solution. We introduce the Helen
    Facial Feature Dataset consisting of annotated portrait images gathered from
    Flickr that are more diverse and challenging than currently existing
    datasets. We present experiments that compare our automatic method to
    published results, and also a quantitative evaluation of the effectiveness
    of our interactive method.
  author:
    - family: Le
      given: Vuong
    - family: Brandt
      given: Jonathan
    - family: Lin
      given: Zhe
    - family: Bourdev
      given: Lubomir
    - family: Huang
      given: Thomas S.
  citation-key: leBrandEtAl2012a
  collection-title: Lecture Notes in Computer Science
  container-title: Computer Vision – ECCV 2012
  DOI: 10.1007/978-3-642-33712-3_49
  editor:
    - family: Fitzgibbon
      given: Andrew
    - family: Lazebnik
      given: Svetlana
    - family: Perona
      given: Pietro
    - family: Sato
      given: Yoichi
    - family: Schmid
      given: Cordelia
  event-place: Berlin, Heidelberg
  ISBN: 978-3-642-33712-3
  issued:
    - year: 2012
  language: en
  page: 679-692
  publisher: Springer
  publisher-place: Berlin, Heidelberg
  source: Springer Link
  title: Interactive Facial Feature Localization
  type: paper-conference

- id: luoLiEtAl2016a
  abstract: >-
    We study characteristics of receptive fields of units in deep convolutional
    networks. The receptive field size is a crucial issue in many visual tasks,
    as the output must respond to large enough areas in the image to capture
    information about large objects. We introduce the notion of an effective
    receptive field, and show that it both has a Gaussian distribution and only
    occupies a fraction of the full theoretical receptive field. We analyze the
    effective receptive field in several architecture designs, and the effect of
    nonlinear activations, dropout, sub-sampling and skip connections on it.
    This leads to suggestions for ways to address its tendency to be too small.
  accessed:
    - year: 2022
      month: 5
      day: 4
  author:
    - family: Luo
      given: Wenjie
    - family: Li
      given: Yujia
    - family: Urtasun
      given: Raquel
    - family: Zemel
      given: Richard
  citation-key: luoLiEtAl2016a
  collection-title: NIPS'16
  container-title: >-
    Proceedings of the 30th International Conference on Neural Information
    Processing Systems
  event-place: Red Hook, NY, USA
  ISBN: 978-1-5108-3881-9
  issued:
    - year: 2016
      month: 12
      day: 5
  page: 4905–4913
  publisher: Curran Associates Inc.
  publisher-place: Red Hook, NY, USA
  source: ACM Digital Library
  title: >-
    Understanding the effective receptive field in deep convolutional neural
    networks
  type: paper-conference

- id: martiValst2016a
  abstract: >-
    In this chapter we consider the problem of automatic facial expression
    analysis. Our take on this is that the field has reached a point where it
    needs to move away from considering experiments and applications under
    in-the-lab conditions, and move towards so-called in-the-wild scenarios. We
    assume throughout this chapter that the aim is to develop technology that
    can be deployed in practical applications under unconstrained conditions.
    While some first efforts in this direction have been reported very recently,
    it is still unclear what the right path to achieving accurate, informative,
    robust, and real-time facial expression analysis will be. To illuminate the
    journey ahead, we first provide in Sect. 1 an overview of the existing
    theories and specific problem formulations considered within the computer
    vision community. Then we describe in Sect. 2 the standard algorithmic
    pipeline which is common to most facial expression analysis algorithms. We
    include suggestions as to which of the current algorithms and approaches are
    most suited to the scenario considered. In Sect. 3 we describe our view of
    the remaining challenges, and the current opportunities within the field.
    This chapter is thus not intended as a review of different approaches, but
    rather a selection of what we believe are the most suitable state-of-the-art
    algorithms, and a selection of exemplars chosen to characterise a specific
    approach. We review in Sect. 4 some of the exciting opportunities for the
    application of automatic facial expression analysis to everyday practical
    problems and current commercial applications being exploited. Section 5 ends
    the chapter by summarising the major conclusions drawn.
  accessed:
    - year: 2022
      month: 5
      day: 1
  author:
    - family: Martinez
      given: Brais
    - family: Valstar
      given: Michel F.
  citation-key: martiValst2016a
  container-title: Advances in Face Detection and Facial Image Analysis
  DOI: 10.1007/978-3-319-25958-1_4
  editor:
    - family: Kawulok
      given: Michal
    - family: Celebi
      given: M. Emre
    - family: Smolka
      given: Bogdan
  event-place: Cham
  ISBN: 978-3-319-25958-1
  issued:
    - year: 2016
  language: en
  page: 63-100
  publisher: Springer International Publishing
  publisher-place: Cham
  source: Springer Link
  title: >-
    Advances, Challenges, and Opportunities in Automatic Facial Expression
    Recognition
  type: chapter
  URL: https://doi.org/10.1007/978-3-319-25958-1_4

- id: matthBaker2004a
  abstract: >-
    Active Appearance Models (AAMs) and the closely related concepts of
    Morphable Models and Active Blobs are generative models of a certain visual
    phenomenon. Although linear in both shape and appearance, overall, AAMs are
    nonlinear parametric models in terms of the pixel intensities. Fitting an
    AAM to an image consists of minimising the error between the input image and
    the closest model instance; i.e. solving a nonlinear optimisation problem.
    We propose an efﬁcient ﬁtting algorithm for AAMs based on the inverse
    compositional image alignment algorithm. We show that the effects of
    appearance variation during ﬁtting can be precomputed (“projected out”)
    using this algorithm and how it can be extended to include a global shape
    normalising warp, typically a 2D similarity transformation. We evaluate our
    algorithm to determine which of its novel aspects improve AAM ﬁtting
    performance.
  accessed:
    - year: 2022
      month: 5
      day: 15
  author:
    - family: Matthews
      given: Iain
    - family: Baker
      given: Simon
  citation-key: matthBaker2004a
  container-title: International Journal of Computer Vision
  container-title-short: International Journal of Computer Vision
  DOI: 10.1023/B:VISI.0000029666.37597.d3
  ISSN: 0920-5691
  issue: '2'
  issued:
    - year: 2004
      month: 11
  language: en
  page: 135-164
  source: DOI.org (Crossref)
  title: Active Appearance Models Revisited
  type: article-journal
  URL: http://link.springer.com/10.1023/B:VISI.0000029666.37597.d3
  volume: '60'

- id: mergeRockEtAl2018a
  accessed:
    - year: 2022
      month: 2
      day: 11
  author:
    - family: Merget
      given: Daniel
    - family: Rock
      given: Matthias
    - family: Rigoll
      given: Gerhard
  citation-key: mergeRockEtAl2018a
  event: >-
    Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition
  issued:
    - year: 2018
  page: 781-790
  source: openaccess.thecvf.com
  title: >-
    Robust Facial Landmark Detection via a Fully-Convolutional Local-Global
    Context Network
  type: paper-conference
  URL: >-
    https://openaccess.thecvf.com/content_cvpr_2018/html/Merget_Robust_Facial_Landmark_CVPR_2018_paper.html

- id: merleRathaEtAl2019a
  abstract: >-
    Face recognition is a long standing challenge in the field of Artificial
    Intelligence (AI). The goal is to create systems that accurately detect,
    recognize, verify, and understand human faces. There are significant
    technical hurdles in making these systems accurate, particularly in
    unconstrained settings due to confounding factors related to pose,
    resolution, illumination, occlusion, and viewpoint. However, with recent
    advances in neural networks, face recognition has achieved unprecedented
    accuracy, largely built on data-driven deep learning methods. While this is
    encouraging, a critical aspect that is limiting facial recognition accuracy
    and fairness is inherent facial diversity. Every face is different. Every
    face reflects something unique about us. Aspects of our heritage - including
    race, ethnicity, culture, geography - and our individual identify - age,
    gender, and other visible manifestations of self-expression, are reflected
    in our faces. We expect face recognition to work equally accurately for
    every face. Face recognition needs to be fair. As we rely on data-driven
    methods to create face recognition technology, we need to ensure necessary
    balance and coverage in training data. However, there are still scientific
    questions about how to represent and extract pertinent facial features and
    quantitatively measure facial diversity. Towards this goal, Diversity in
    Faces (DiF) provides a data set of one million annotated human face images
    for advancing the study of facial diversity. The annotations are generated
    using ten well-established facial coding schemes from the scientific
    literature. The facial coding schemes provide human-interpretable
    quantitative measures of facial features. We believe that by making the
    extracted coding schemes available on a large set of faces, we can
    accelerate research and development towards creating more fair and accurate
    facial recognition systems.
  accessed:
    - year: 2021
      month: 11
      day: 23
  author:
    - family: Merler
      given: Michele
    - family: Ratha
      given: Nalini
    - family: Feris
      given: Rogerio S.
    - family: Smith
      given: John R.
  citation-key: merleRathaEtAl2019a
  container-title: arXiv:1901.10436 [cs]
  issued:
    - year: 2019
      month: 4
      day: 8
  source: arXiv.org
  title: Diversity in Faces
  type: article-journal
  URL: http://arxiv.org/abs/1901.10436

- id: mobm2008a
  accessed:
    - year: 2022
      month: 5
      day: 10
  author:
    - literal: mob mob
  citation-key: mobm2008a
  issued:
    - year: 2008
      month: 5
      day: 28
  medium: photo
  source: Flickr
  title: Sleeping Baby
  type: graphic
  URL: https://www.flickr.com/photos/biblicone/2533285432/

- id: murphTrive2009a
  abstract: >-
    The capacity to estimate the head pose of another person is a common human
    ability that presents a unique challenge for computer vision systems.
    Compared to face detection and recognition, which have been the primary foci
    of face-related vision research, identity-invariant head pose estimation has
    fewer rigorously evaluated systems or generic solutions. In this paper, we
    discuss the inherent difficulties in head pose estimation and present an
    organized survey describing the evolution of the field. Our discussion
    focuses on the advantages and disadvantages of each approach and spans 90 of
    the most innovative and characteristic papers that have been published on
    this topic. We compare these systems by focusing on their ability to
    estimate coarse and fine head pose, highlighting approaches that are well
    suited for unconstrained environments.
  author:
    - family: Murphy-Chutorian
      given: Erik
    - family: Trivedi
      given: Mohan Manubhai
  citation-key: murphTrive2009a
  container-title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  DOI: 10.1109/TPAMI.2008.106
  ISSN: 1939-3539
  issue: '4'
  issued:
    - year: 2009
      month: 4
  page: 607-626
  source: IEEE Xplore
  title: 'Head Pose Estimation in Computer Vision: A Survey'
  title-short: Head Pose Estimation in Computer Vision
  type: article-journal
  volume: '31'

- id: nadaSindaEtAl2018a
  abstract: >-
    Face detection has witnessed immense progress in the last few years, with
    new milestones being surpassed every year. While many challenges such as
    large variations in scale, pose, appearance are successfully addressed,
    there still exist several issues which are not specifically captured by
    existing methods or datasets. In this work, we identify the next set of
    challenges that requires attention from the research community and collect a
    new dataset of face images that involve these issues such as weather-based
    degradations, motion blur, focus blur and several others. We demonstrate
    that there is a considerable gap in the performance of state-of-the-art
    detectors and real-world requirements. Hence, in an attempt to fuel further
    research in unconstrained face detection, we present a new annotated
    Unconstrained Face Detection Dataset (UFDD) with several challenges and
    benchmark recent methods. Additionally, we provide an in-depth analysis of
    the results and failure cases of these methods. The UFDD dataset as well as
    baseline results, evaluation code and image source are available at:
    www.ufdd.info/.
  author:
    - family: Nada
      given: Hajime
    - family: Sindagi
      given: Vishwanath A.
    - family: Zhang
      given: He
    - family: Patel
      given: Vishal M.
  citation-key: nadaSindaEtAl2018a
  container-title: >-
    2018 IEEE 9th International Conference on Biometrics Theory, Applications
    and Systems (BTAS)
  DOI: 10.1109/BTAS.2018.8698561
  event: >-
    2018 IEEE 9th International Conference on Biometrics Theory, Applications
    and Systems (BTAS)
  ISSN: 2474-9699
  issued:
    - year: 2018
      month: 10
  page: 1-10
  source: IEEE Xplore
  title: >-
    Pushing the Limits of Unconstrained Face Detection: a Challenge Dataset and
    Baseline Results
  title-short: Pushing the Limits of Unconstrained Face Detection
  type: paper-conference

- id: nixonAguad2019a
  abstract: >-
    Feature Extraction for Image Processing and Computer Vision is an essential
    guide to the implementation of image processing and computer vision
    techniques, with tutorial introductions and sample code in MATLAB and
    Python. Algorithms are presented and fully explained to enable complete
    understanding of the methods and techniques demonstrated. As one reviewer
    noted, "The main strength of the proposed book is the link between theory
    and exemplar code of the algorithms." Essential background theory is
    carefully explained.


    This text gives students and researchers in image processing and computer
    vision a complete introduction to classic and state-of-the art methods in
    feature extraction together with practical guidance on their implementation.
  author:
    - family: Nixon
      given: Mark S.
    - family: Aguado
      given: Alberto S.
  citation-key: nixonAguad2019a
  DOI: 10.1016/C2017-0-02153-5
  edition: Fourth
  ISBN: 978-0-12-814976-8
  issued:
    - year: 2019
      month: 11
      day: 17
  language: en
  number-of-pages: '818'
  publisher: Academic Press
  source: ScienceDirect
  title: Feature Extraction and Image Processing for Computer Vision
  type: book
  URL: >-
    https://www.sciencedirect.com/book/9780128149768/feature-extraction-and-image-processing-for-computer-vision

- id: paper1966a
  abstract: >-
    The summer vision project is an attempt to use our summer workers
    effectively in the construction of a significant part of a visual system.
    The particular task was chosen partly because it can be segmented into
    sub-problems which allow individuals to work independently and yet
    participate in the construction of a system complex enough to be real
    landmark in the development of "pattern recognition". The basic structure is
    fixed for the first phase of work extending to some point in July. Everyone
    is invited to contribute to the discussion of the second phase. Sussman is
    coordinator of "Vision Project" meetings and should be consulted by anyone
    who wishes to participate. The primary goal of the project is to construct a
    system of programs which will divide a vidisector picture into regions such
    as likely objects, likely background areas and chaos. We shall call this
    part of its operation FIGURE-GROUND analysis. It will be impossible to do
    this without considerable analysis of shape and surface properties, so
    FIGURE-GROUND analysis is really inseparable in practice from the second
    goal which is REGION DESCRIPTION. The final goal is OBJECT IDENTIFICATION
    which will actually name objects by matching them with a vocabulary of known
    objects.
  accessed:
    - year: 2022
      month: 5
      day: 14
  author:
    - family: Papert
      given: Seymour A.
  citation-key: paper1966a
  container-title: AI Memos (1959 - 2004)
  issued:
    - year: 1966
      month: 7
      day: 1
  language: en_US
  note: 'Accepted: 2004-10-04T14:40:06Z'
  source: dspace.mit.edu
  title: The Summer Vision Project
  type: article-journal
  URL: https://dspace.mit.edu/handle/1721.1/6125

- id: princ2012a
  author:
    - family: Prince
      given: Simon J. D.
  citation-key: princ2012a
  edition: 1st edition
  event-place: New York
  ISBN: 978-1-107-01179-3
  issued:
    - year: 2012
      month: 6
      day: 18
  language: English
  number-of-pages: '598'
  publisher: Cambridge University Press
  publisher-place: New York
  source: Amazon
  title: 'Computer Vision: Models, Learning, and Inference'
  title-short: Computer Vision
  type: book

- id: rowleBalujEtAl1998a
  abstract: >-
    We present a neural network-based upright frontal face detection system. A
    retinally connected neural network examines small windows of an image and
    decides whether each window contains a face. The system arbitrates between
    multiple networks to improve performance over a single network. We present a
    straightforward procedure for aligning positive face examples for training.
    To collect negative examples, we use a bootstrap algorithm, which adds false
    detections into the training set as training progresses. This eliminates the
    difficult task of manually selecting nonface training examples, which must
    be chosen to span the entire space of nonface images. Simple heuristics,
    such as using the fact that faces rarely overlap in images, can further
    improve the accuracy. Comparisons with several other state-of-the-art face
    detection systems are presented, showing that our system has comparable
    performance in terms of detection and false-positive rates.
  author:
    - family: Rowley
      given: H.A.
    - family: Baluja
      given: S.
    - family: Kanade
      given: T.
  citation-key: rowleBalujEtAl1998a
  container-title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  DOI: 10.1109/34.655647
  ISSN: 1939-3539
  issue: '1'
  issued:
    - year: 1998
      month: 1
  page: 23-38
  source: IEEE Xplore
  title: Neural network-based face detection
  type: article-journal
  volume: '20'

- id: sagonAntonEtAl2016a
  abstract: >-
    Computer Vision has recently witnessed great research advance towards
    automatic facial points detection. Numerous methodologies have been proposed
    during the last few years that achieve accurate and efficient performance.
    However, fair comparison between these methodologies is infeasible mainly
    due to two issues. (a) Most existing databases, captured under both
    constrained and unconstrained (in-the-wild) conditions have been annotated
    using different mark-ups and, in most cases, the accuracy of the annotations
    is low. (b) Most published works report experimental results using different
    training/testing sets, different error metrics and, of course, landmark
    points with semantically different locations. In this paper, we aim to
    overcome the aforementioned problems by (a) proposing a semi-automatic
    annotation technique that was employed to re-annotate most existing facial
    databases under a unified protocol, and (b) presenting the 300 Faces
    In-The-Wild Challenge (300-W), the first facial landmark localization
    challenge that was organized twice, in 2013 and 2015. To the best of our
    knowledge, this is the first effort towards a unified annotation scheme of
    massive databases and a fair experimental comparison of existing facial
    landmark localization systems. The images and annotations of the new testing
    database that was used in the 300-W challenge are available from
    http://ibug.doc.ic.ac.uk/resources/300-W_IMAVIS/.
  accessed:
    - year: 2022
      month: 4
      day: 30
  author:
    - family: Sagonas
      given: Christos
    - family: Antonakos
      given: Epameinondas
    - family: Tzimiropoulos
      given: Georgios
    - family: Zafeiriou
      given: Stefanos
    - family: Pantic
      given: Maja
  citation-key: sagonAntonEtAl2016a
  collection-title: 300-W, the First Automatic Facial Landmark Detection in-the-Wild Challenge
  container-title: Image and Vision Computing
  container-title-short: Image and Vision Computing
  DOI: 10.1016/j.imavis.2016.01.002
  ISSN: 0262-8856
  issued:
    - year: 2016
      month: 3
      day: 1
  language: en
  page: 3-18
  source: ScienceDirect
  title: '300 Faces In-The-Wild Challenge: database and results'
  title-short: 300 Faces In-The-Wild Challenge
  type: article-journal
  URL: https://www.sciencedirect.com/science/article/pii/S0262885616000147
  volume: '47'

- id: sagonTzimiEtAl2013a
  abstract: >-
    Developing powerful deformable face models requires massive, annotated face
    databases on which techniques can be trained, validated and tested. Manual
    annotation of each facial image in terms of landmarks requires a trained
    expert and the workload is usually enormous. Fatigue is one of the reasons
    that in some cases annotations are inaccurate. This is why, the majority of
    existing facial databases provide annotations for a relatively small subset
    of the training images. Furthermore, there is hardly any correspondence
    between the annotated land-marks across different databases. These problems
    make cross-database experiments almost infeasible. To overcome these
    difficulties, we propose a semi-automatic annotation methodology for
    annotating massive face datasets. This is the first attempt to create a tool
    suitable for annotating massive facial databases. We employed our tool for
    creating annotations for MultiPIE, XM2VTS, AR, and FRGC Ver. 2 databases.
    The annotations will be made publicly available from
    http://ibug.doc.ic.ac.uk/ resources/facial-point-annotations/. Finally, we
    present experiments which verify the accuracy of produced annotations.
  author:
    - family: Sagonas
      given: Christos
    - family: Tzimiropoulos
      given: Georgios
    - family: Zafeiriou
      given: Stefanos
    - family: Pantic
      given: Maja
  citation-key: sagonTzimiEtAl2013a
  container-title: 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops
  DOI: 10.1109/CVPRW.2013.132
  event: 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops
  ISSN: 2160-7516
  issued:
    - year: 2013
      month: 6
  page: 896-903
  source: IEEE Xplore
  title: A Semi-automatic Methodology for Facial Landmark Annotation
  type: paper-conference

- id: sagonTzimiEtAl2013b
  abstract: >-
    Automatic facial point detection plays arguably the most important role in
    face analysis. Several methods have been proposed which reported their
    results on databases of both constrained and unconstrained conditions. Most
    of these databases provide annotations with different mark-ups and in some
    cases the are problems related to the accuracy of the fiducial points. The
    aforementioned issues as well as the lack of a evaluation protocol makes it
    difficult to compare performance between different systems. In this paper,
    we present the 300 Faces in-the-Wild Challenge: The first facial landmark
    localization Challenge which is held in conjunction with the International
    Conference on Computer Vision 2013, Sydney, Australia. The main goal of this
    challenge is to compare the performance of different methods on a
    new-collected dataset using the same evaluation protocol and the same
    mark-up and hence to develop the first standardized benchmark for facial
    landmark localization.
  author:
    - family: Sagonas
      given: Christos
    - family: Tzimiropoulos
      given: Georgios
    - family: Zafeiriou
      given: Stefanos
    - family: Pantic
      given: Maja
  citation-key: sagonTzimiEtAl2013b
  container-title: 2013 IEEE International Conference on Computer Vision Workshops
  DOI: 10.1109/ICCVW.2013.59
  event: 2013 IEEE International Conference on Computer Vision Workshops
  issued:
    - year: 2013
      month: 12
  page: 397-403
  source: IEEE Xplore
  title: >-
    300 Faces in-the-Wild Challenge: The First Facial Landmark Localization
    Challenge
  title-short: 300 Faces in-the-Wild Challenge
  type: paper-conference

- id: saragLuceyEtAl2011a
  abstract: >-
    Deformable model fitting has been actively pursued in the computer vision
    community for over a decade. As a result, numerous approaches have been
    proposed with varying degrees of success. A class of approaches that has
    shown substantial promise is one that makes independent predictions
    regarding locations of the model’s landmarks, which are combined by
    enforcing a prior over their joint motion. A common theme in innovations to
    this approach is the replacement of the distribution of probable landmark
    locations, obtained from each local detector, with simpler parametric forms.
    In this work, a principled optimization strategy is proposed where
    nonparametric representations of these likelihoods are maximized within a
    hierarchy of smoothed estimates. The resulting update equations are
    reminiscent of mean-shift over the landmarks but with regularization imposed
    through a global prior over their joint motion. Extensions to handle partial
    occlusions and reduce computational complexity are also presented. Through
    numerical experiments, this approach is shown to outperform some common
    existing methods on the task of generic face fitting.
  accessed:
    - year: 2022
      month: 4
      day: 25
  author:
    - family: Saragih
      given: Jason M.
    - family: Lucey
      given: Simon
    - family: Cohn
      given: Jeffrey F.
  citation-key: saragLuceyEtAl2011a
  container-title: International Journal of Computer Vision
  container-title-short: Int J Comput Vis
  DOI: 10.1007/s11263-010-0380-4
  ISSN: 1573-1405
  issue: '2'
  issued:
    - year: 2011
      month: 1
      day: 1
  language: en
  page: 200-215
  source: Springer Link
  title: Deformable Model Fitting by Regularized Landmark Mean-Shift
  type: article-journal
  URL: https://doi.org/10.1007/s11263-010-0380-4
  volume: '91'

- id: stegm2000a
  abstract: >-
    This thesis presents a general approach towards image segmentation using the
    learning-based deformable model Active Appearance Model (AAM) proposed by
    Cootes et al. The primary advantage of AAMs is that a priori knowledge is
    learned through observation of both shape and texture variation in a
    training set. From this, a compact object class description is derived,
    which can be used to rapidly search images for new object instances. A
    thorough treatment and discussion of the theory behind AAMs is given,
    followed by several extensions to the basic AAM, which constitutes the major
    contribution of this thesis. Extensions include automatic initialization and
    unification of finite element models and AAMs. All of these have been
    implemented in a structured and fast C++ framework; the AAM-API. Finally,
    case studies based on radiographs of metacarpals, cardiovascular magnetic
    resonance images and perspective images of pork carcass are presented.
    Herein the performance of the basic AAM and the developed extensions are
    assessment using leave-one-out evaluation. It is concluded that AAMs – as a
    data-driven and fully automated method – successfully can perform object
    segmentation in challenging and very different image modalities with very
    high accuracy. In two of three cases subpixel accuracy were obtained w.r.t.
    object segmentation.
  author:
    - family: Stegmann
      given: M. B.
  citation-key: stegm2000a
  edition: '2'
  event-place: Richard Petersens Plads, Building 321, DK-2800 Kgs. Lyngby
  issued:
    - year: 2000
      month: 8
  page: '262'
  publisher: Informatics and Mathematical Modelling, Technical University of Denmark, DTU
  publisher-place: Richard Petersens Plads, Building 321, DK-2800 Kgs. Lyngby
  title: 'Active appearance models: Theory, extensions and cases'
  type: thesis
  URL: http://www.imm.dtu.dk/~aam/main/

- id: stegm2002a
  abstract: >-
    This report provides an analysis of 37 annotated frontal face images. All
    results presented have been obtained using our freely available Active
    Appearance Model (AAM) implementation. To ensure the reproducibility of the
    presented experiments, the data set has also been made available. As such,
    the data and this report may serve as a point of reference to compare other
    AAM implementations against. In addition, we address the problem of AAM
    model truncation using parallel analysis along with a comparable study of
    the two prevalent AAM learning methods; principal component regression and
    estimation of ﬁxed Jacobian matrices. To assess applicability and eﬃciency,
    timings for model building, warping and optimisation are given together with
    a description of how to exploit the warping capabilities of contemporary
    consumer-level graphics hardware.
  author:
    - family: Stegmann
      given: Mikkel B
  citation-key: stegm2002a
  issued:
    - year: 2002
      month: 8
  language: en
  page: '25'
  title: >-
    Analysis and Segmentation of Face Images using Point Annotations and Linear
    Subspace Techniques
  type: article-journal
  URL: http://www2.imm.dtu.dk/pubdb/edoc/imm922.pdf

- id: sunWangEtAl2013a
  abstract: >-
    We propose a new approach for estimation of the positions of facial key
    points with three-level carefully designed convolutional networks. At each
    level, the outputs of multiple networks are fused for robust and accurate
    estimation. Thanks to the deep structures of convolutional networks, global
    high-level features are extracted over the whole face region at the
    initialization stage, which help to locate high accuracy key points. There
    are two folds of advantage for this. First, the texture context information
    over the entire face is utilized to locate each key point. Second, since the
    networks are trained to predict all the key points simultaneously, the
    geometric constraints among key points are implicitly encoded. The method
    therefore can avoid local minimum caused by ambiguity and data corruption in
    difficult image samples due to occlusions, large pose variations, and
    extreme lightings. The networks at the following two levels are trained to
    locally refine initial predictions and their inputs are limited to small
    regions around the initial predictions. Several network structures critical
    for accurate and robust facial point detection are investigated. Extensive
    experiments show that our approach outperforms state-of-the-art methods in
    both detection accuracy and reliability.
  author:
    - family: Sun
      given: Yi
    - family: Wang
      given: Xiaogang
    - family: Tang
      given: Xiaoou
  citation-key: sunWangEtAl2013a
  container-title: 2013 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2013.446
  event: 2013 IEEE Conference on Computer Vision and Pattern Recognition
  ISSN: 1063-6919
  issued:
    - year: 2013
      month: 6
  note: 'Implementation: https://mmlab.ie.cuhk.edu.hk/archive/CNN/'
  page: 3476-3483
  source: IEEE Xplore
  title: Deep Convolutional Network Cascade for Facial Point Detection
  type: paper-conference

- id: szeli2022a
  accessed:
    - year: 2022
      month: 5
      day: 14
  author:
    - family: Szeliski
      given: Richard
  citation-key: szeli2022a
  collection-title: Texts in Computer Science
  DOI: 10.1007/978-3-030-34372-9
  event-place: Cham
  ISBN: 978-3-030-34371-2 978-3-030-34372-9
  issued:
    - year: 2022
  language: en
  publisher: Springer International Publishing
  publisher-place: Cham
  source: DOI.org (Crossref)
  title: 'Computer Vision: Algorithms and Applications'
  title-short: Computer Vision
  type: book
  URL: https://link.springer.com/10.1007/978-3-030-34372-9

- id: taigmYangEtAl2014a
  abstract: >-
    In modern face recognition, the conventional pipeline consists of four
    stages: detect => align => represent => classify. We revisit both the
    alignment step and the representation step by employing explicit 3D face
    modeling in order to apply a piecewise affine transformation, and derive a
    face representation from a nine-layer deep neural network. This deep network
    involves more than 120 million parameters using several locally connected
    layers without weight sharing, rather than the standard convolutional
    layers. Thus we trained it on the largest facial dataset to-date, an
    identity labeled dataset of four million facial images belonging to more
    than 4, 000 identities. The learned representations coupling the accurate
    model-based alignment with the large facial database generalize remarkably
    well to faces in unconstrained environments, even with a simple classifier.
    Our method reaches an accuracy of 97.35% on the Labeled Faces in the Wild
    (LFW) dataset, reducing the error of the current state of the art by more
    than 27%, closely approaching human-level performance.
  author:
    - family: Taigman
      given: Yaniv
    - family: Yang
      given: Ming
    - family: Ranzato
      given: Marc'Aurelio
    - family: Wolf
      given: Lior
  citation-key: taigmYangEtAl2014a
  container-title: 2014 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2014.220
  event: 2014 IEEE Conference on Computer Vision and Pattern Recognition
  ISSN: 1063-6919
  issued:
    - year: 2014
      month: 6
  page: 1701-1708
  source: IEEE Xplore
  title: 'DeepFace: Closing the Gap to Human-Level Performance in Face Verification'
  title-short: DeepFace
  type: paper-conference

- id: tzimiPanti2013a
  abstract: >-
    We describe a very simple framework for deriving the most-well known
    optimization problems in Active Appearance Models (AAMs), and most
    importantly for providing efﬁcient solutions. Our formulation results in two
    optimization problems for fast and exact AAM ﬁtting, and one new algorithm
    which has the important advantage of being applicable to 3D. We show that
    the dominant cost for both forward and inverse algorithms is a few times mN
    which is the cost of projecting an image onto the appearance subspace. This
    makes both algorithms not only computationally realizable but also very
    attractive speed-wise for most current systems. Because exact AAM ﬁtting is
    no longer computationally prohibitive, we trained AAMs in-the-wild with the
    goal of investigating whether AAMs beneﬁt from such a training process. Our
    results show that although we did not use sophisticated shape priors, robust
    features or robust norms for improving performance, AAMs perform notably
    well and in some cases comparably with current state-ofthe-art methods. We
    provide Matlab source code for training, ﬁtting and reproducing the results
    presented in this paper at http://ibug.doc.ic.ac.uk/resources.
  accessed:
    - year: 2022
      month: 5
      day: 10
  author:
    - family: Tzimiropoulos
      given: Georgios
    - family: Pantic
      given: Maja
  citation-key: tzimiPanti2013a
  container-title: 2013 IEEE International Conference on Computer Vision
  DOI: 10.1109/ICCV.2013.79
  event: 2013 IEEE International Conference on Computer Vision (ICCV)
  event-place: Sydney, Australia
  ISBN: 978-1-4799-2840-8
  issued:
    - year: 2013
      month: 12
  language: en
  note: >-
    Implementation:
    https://ibug.doc.ic.ac.uk/resources/fitting-aams-wild-iccv-2013/
  page: 593-600
  publisher: IEEE
  publisher-place: Sydney, Australia
  source: DOI.org (Crossref)
  title: Optimization Problems for Fast AAM Fitting in-the-Wild
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/6751183/

- id: tzimiZafeiEtAl2011a
  abstract: >-
    We propose a correlation-based approach to parametric object alignment
    particularly suitable for face analysis applications which require
    efficiency and robustness against occlusions and illumination changes. Our
    algorithm registers two images by iteratively maximizing their correlation
    coefficient using gradient ascent. We compute this correlation coefficient
    from complex gradients which capture the orientation of image structures
    rather than pixel intensities. The maximization of this gradient correlation
    coefficient results in an algorithm which is as computationally efficient as
    ℓ2 norm-based algorithms, can be extended within the inverse compositional
    framework (without the need for Hessian recomputation) and is robust to
    outliers. To the best of our knowledge, no other algorithm has been proposed
    so far having all three features. We show the robustness of our algorithm
    for the problem of face alignment in the presence of occlusions and
    non-uniform illumination changes. The code that reproduces the results of
    our paper can be found at http://ibug.doc.ic.ac.uk/resources.
  author:
    - family: Tzimiropoulos
      given: Georgios
    - family: Zafeiriou
      given: Stefanos
    - family: Pantic
      given: Maja
  citation-key: tzimiZafeiEtAl2011a
  container-title: 2011 International Conference on Computer Vision
  DOI: 10.1109/ICCV.2011.6126452
  event: 2011 International Conference on Computer Vision
  ISSN: 2380-7504
  issued:
    - year: 2011
      month: 11
  page: 1847-1854
  source: IEEE Xplore
  title: Robust and efficient parametric face alignment
  type: paper-conference

- id: tzimiZafeiEtAl2012a
  abstract: >-
    We introduce the notion of subspace learning from image gradient
    orientations for appearance-based object recognition. As image data are
    typically noisy and noise is substantially different from Gaussian,
    traditional subspace learning from pixel intensities very often fails to
    estimate reliably the low-dimensional subspace of a given data population.
    We show that replacing pixel intensities with gradient orientations and the
    ℓ2 norm with a cosine-based distance measure offers, to some extend, a
    remedy to this problem. Within this framework, which we coin Image Gradient
    Orientations (IGO) subspace learning, we first formulate and study the
    properties of Principal Component Analysis of image gradient orientations
    (IGO-PCA). We then show its connection to previously proposed robust PCA
    techniques both theoretically and experimentally. Finally, we derive a
    number of other popular subspace learning techniques, namely, Linear
    Discriminant Analysis (LDA), Locally Linear Embedding (LLE), and Laplacian
    Eigenmaps (LE). Experimental results show that our algorithms significantly
    outperform popular methods such as Gabor features and Local Binary Patterns
    and achieve state-of-the-art performance for difficult problems such as
    illumination and occlusion-robust face recognition. In addition to this, the
    proposed IGO-methods require the eigendecomposition of simple covariance
    matrices and are as computationally efficient as their corresponding ℓ2 norm
    intensity-based counterparts. Matlab code for the methods presented in this
    paper can be found at http://ibug.doc.ic.ac.uk/resources.
  author:
    - family: Tzimiropoulos
      given: Georgios
    - family: Zafeiriou
      given: Stefanos
    - family: Pantic
      given: Maja
  citation-key: tzimiZafeiEtAl2012a
  container-title: IEEE Transactions on Pattern Analysis and Machine Intelligence
  DOI: 10.1109/TPAMI.2012.40
  ISSN: 1939-3539
  issue: '12'
  issued:
    - year: 2012
      month: 12
  page: 2454-2466
  source: IEEE Xplore
  title: Subspace Learning from Image Gradient Orientations
  type: article-journal
  volume: '34'

- id: violaJones2001a
  abstract: >-
    This paper describes a machine learning approach for visual object detection
    which is capable of processing images extremely rapidly and achieving high
    detection rates. This work is distinguished by three key contributions. The
    ﬁrst is the introduction of a new image representation called the “Integral
    Image” which allows the features used by our detector to be computed very
    quickly. The second is a learning algorithm, based on AdaBoost, which
    selects a small number of critical visual features from a larger set and
    yields extremely efﬁcient classiﬁers[6]. The third contribution is a method
    for combining increasingly more complex classiﬁers in a “cascade” which
    allows background regions of the image to be quickly discarded while
    spending more computation on promising object-like regions. The cascade can
    be viewed as an object speciﬁc focus-of-attention mechanism which unlike
    previous approaches provides statistical guarantees that discarded regions
    are unlikely to contain the object of interest. In the domain of face
    detection the system yields detection rates comparable to the best previous
    systems. Used in real-time applications, the detector runs at 15 frames per
    second without resorting to image differencing or skin color detection.
  accessed:
    - year: 2022
      month: 5
      day: 4
  author:
    - family: Viola
      given: P.
    - family: Jones
      given: M.
  citation-key: violaJones2001a
  container-title: >-
    Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision
    and Pattern Recognition. CVPR 2001
  DOI: 10.1109/CVPR.2001.990517
  event: >-
    2001 IEEE Computer Society Conference on Computer Vision and Pattern
    Recognition. CVPR 2001
  event-place: Kauai, HI, USA
  ISBN: 978-0-7695-1272-3
  issued:
    - year: 2001
      month: 12
      day: 8
  language: en
  page: I-511-I-518
  publisher: IEEE Comput. Soc
  publisher-place: Kauai, HI, USA
  source: DOI.org (Crossref)
  title: Rapid object detection using a boosted cascade of simple features
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/990517/
  volume: '1'

- id: wuJi2019a
  abstract: >-
    The locations of the fiducial facial landmark points around facial
    components and facial contour capture the rigid and non-rigid facial
    deformations due to head movements and facial expressions. They are hence
    important for various facial analysis tasks. Many facial landmark detection
    algorithms have been developed to automatically detect those key points over
    the years, and in this paper, we perform an extensive review of them. We
    classify the facial landmark detection algorithms into three major
    categories: holistic methods, Constrained Local Model (CLM) methods, and the
    regression-based methods. They differ in the ways to utilize the facial
    appearance and shape information. The holistic methods explicitly build
    models to represent the global facial appearance and shape information. The
    CLMs explicitly leverage the global shape model but build the local
    appearance models. The regression based methods implicitly capture facial
    shape and appearance information. For algorithms within each category, we
    discuss their underlying theories as well as their differences. We also
    compare their performances on both controlled and in the wild benchmark
    datasets, under varying facial expressions, head poses, and occlusion. Based
    on the evaluations, we point out their respective strengths and weaknesses.
    There is also a separate section to review the latest deep learning based
    algorithms. The survey also includes a listing of the benchmark databases
    and existing software. Finally, we identify future research directions,
    including combining methods in different categories to leverage their
    respective strengths to solve landmark detection “in-the-wild”.
  accessed:
    - year: 2022
      month: 2
      day: 11
  author:
    - family: Wu
      given: Yue
    - family: Ji
      given: Qiang
  citation-key: wuJi2019a
  container-title: International Journal of Computer Vision
  container-title-short: Int J Comput Vis
  DOI: 10.1007/s11263-018-1097-z
  ISSN: 1573-1405
  issue: '2'
  issued:
    - year: 2019
      month: 2
      day: 1
  language: en
  page: 115-142
  source: Springer Link
  title: 'Facial Landmark Detection: A Literature Survey'
  title-short: Facial Landmark Detection
  type: article-journal
  URL: https://doi.org/10.1007/s11263-018-1097-z
  volume: '127'

- id: xiongDeLala2013a
  abstract: >-
    Many computer vision problems (e.g., camera calibration, image alignment,
    structure from motion) are solved through a nonlinear optimization method.
    It is generally accepted that 2nd order descent methods are the most robust,
    fast and reliable approaches for nonlinear optimization of a general smooth
    function. However, in the context of computer vision, 2nd order descent
    methods have two main drawbacks: (1) The function might not be analytically
    differentiable and numerical approximations are impractical. (2) The Hessian
    might be large and not positive definite. To address these issues, this
    paper proposes a Supervised Descent Method (SDM) for minimizing a Non-linear
    Least Squares (NLS) function. During training, the SDM learns a sequence of
    descent directions that minimizes the mean of NLS functions sampled at
    different points. In testing, SDM minimizes the NLS objective using the
    learned descent directions without computing the Jacobian nor the Hessian.
    We illustrate the benefits of our approach in synthetic and real examples,
    and show how SDM achieves state-of-the-art performance in the problem of
    facial feature detection. The code is available at www.humansensing.cs.
    cmu.edu/intraface.
  author:
    - family: Xiong
      given: Xuehan
    - family: De la Torre
      given: Fernando
  citation-key: xiongDeLala2013a
  container-title: 2013 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2013.75
  event: 2013 IEEE Conference on Computer Vision and Pattern Recognition
  ISSN: 1063-6919
  issued:
    - year: 2013
      month: 6
  page: 532-539
  source: IEEE Xplore
  title: Supervised Descent Method and Its Applications to Face Alignment
  type: paper-conference

- id: yanLeiEtAl2013a
  abstract: >-
    In this paper, we present the details of our method in attending the 300
    Faces in-the-wild (300W) challenge. We build our method on cascade
    regression framework, where a series of regressors are utilized to
    progressively reﬁne the shape initialized by face detector. In cascade
    regression, we use the HOG feature in a multi-scale manner, where the large
    pose validation is handled in early stages by HOG feature at large scale,
    and then shape is reﬁned at later stages with HOG feature at small scale. We
    observe that the performance of the cascade regression method decreases when
    the initialization provided by face detector is not accurate enough (for
    faces with large appearance variations, face detection is still a
    challenging problem). To handle the problem, we propose to generate multiple
    hypotheses, and then learn to rank or combine these hypotheses to get the
    ﬁnal result. The parameters in both learn to rank and learn to combine can
    be learned in a structural SVM framework. Despite the simplicity of our
    method, it achieves state-ofthe-art performance on LFPW, and dramatically
    outperforms the baseline AAM on the 300-W challenge.
  accessed:
    - year: 2022
      month: 5
      day: 4
  author:
    - family: Yan
      given: Junjie
    - family: Lei
      given: Zhen
    - family: Yi
      given: Dong
    - family: Li
      given: Stan Z.
  citation-key: yanLeiEtAl2013a
  container-title: 2013 IEEE International Conference on Computer Vision Workshops
  DOI: 10.1109/ICCVW.2013.126
  event: 2013 IEEE International Conference on Computer Vision Workshops (ICCVW)
  event-place: Sydney, Australia
  ISBN: 978-1-4799-3022-7
  issued:
    - year: 2013
      month: 12
  language: en
  page: 392-396
  publisher: IEEE
  publisher-place: Sydney, Australia
  source: DOI.org (Crossref)
  title: Learn to Combine Multiple Hypotheses for Accurate Face Alignment
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/6755924/

- id: zadehBaltrEtAl2017a
  abstract: >-
    Constrained Local Models (CLMs) are a well-established family of methods for
    facial landmark detection. However, they have recently fallen out of favor
    to cascaded regressionbased approaches. This is in part due to the inability
    of existing CLM local detectors to model the very complex individual
    landmark appearance that is affected by expression, illumination, facial
    hair, makeup, and accessories. In our work, we present a novel local
    detector – Convolutional Experts Network (CEN) – that brings together the
    advantages of neural architectures and mixtures of experts in an end-toend
    framework. We further propose a Convolutional Experts Constrained Local
    Model (CE-CLM) algorithm that uses CEN as a local detector. We demonstrate
    that our proposed CE-CLM algorithm outperforms competitive state-of-the-art
    baselines for facial landmark detection by a large margin, especially on
    challenging proﬁle images.
  accessed:
    - year: 2022
      month: 5
      day: 8
  author:
    - family: Zadeh
      given: Amir
    - family: Baltrusaitis
      given: Tadas
    - family: Morency
      given: Louis-Philippe
  citation-key: zadehBaltrEtAl2017a
  container-title: >-
    2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops
    (CVPRW)
  DOI: 10.1109/CVPRW.2017.256
  event: >-
    2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops
    (CVPRW)
  event-place: Honolulu, HI, USA
  ISBN: 978-1-5386-0733-6
  issued:
    - year: 2017
      month: 7
  language: en
  page: 2051-2059
  publisher: IEEE
  publisher-place: Honolulu, HI, USA
  source: DOI.org (Crossref)
  title: Convolutional Experts Constrained Local Model for Facial Landmark Detection
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/8014990/

- id: zafeiZhangEtAl2015a
  abstract: >-
    Face detection is one of the most studied topics in computer vision
    literature, not only because of the challenging nature of face as an object,
    but also due to the countless applications that require the application of
    face detection as a first step. During the past 15years, tremendous progress
    has been made due to the availability of data in unconstrained capture
    conditions (so-called ‘in-the-wild’) through the Internet, the effort made
    by the community to develop publicly available benchmarks, as well as the
    progress in the development of robust computer vision algorithms. In this
    paper, we survey the recent advances in real-world face detection
    techniques, beginning with the seminal Viola–Jones face detector
    methodology. These techniques are roughly categorized into two general
    schemes: rigid templates, learned mainly via boosting based methods or by
    the application of deep neural networks, and deformable models that describe
    the face by its parts. Representative methods will be described in detail,
    along with a few additional successful methods that we briefly go through at
    the end. Finally, we survey the main databases used for the evaluation of
    face detection algorithms and recent benchmarking efforts, and discuss the
    future of face detection.
  accessed:
    - year: 2021
      month: 11
      day: 23
  author:
    - family: Zafeiriou
      given: Stefanos
    - family: Zhang
      given: Cha
    - family: Zhang
      given: Zhengyou
  citation-key: zafeiZhangEtAl2015a
  container-title: Computer Vision and Image Understanding
  container-title-short: Computer Vision and Image Understanding
  DOI: 10.1016/j.cviu.2015.03.015
  ISSN: 1077-3142
  issued:
    - year: 2015
      month: 9
      day: 1
  language: en
  page: 1-24
  source: ScienceDirect
  title: 'A survey on face detection in the wild: Past, present and future'
  title-short: A survey on face detection in the wild
  type: article-journal
  URL: https://www.sciencedirect.com/science/article/pii/S1077314215000727
  volume: '138'

- id: zhouFanEtAl2013a
  abstract: >-
    We present a new approach to localize extensive facial landmarks with a
    coarse-to-ﬁne convolutional network cascade. Deep convolutional neural
    networks (DCNN) have been successfully utilized in facial landmark
    localization for two-fold advantages: 1) geometric constraints among facial
    points are implicitly utilized; 2) huge amount of training data can be
    leveraged. However, in the task of extensive facial landmark localization, a
    large number of facial landmarks (more than 50 points) are required to be
    located in a uniﬁed system, which poses great difﬁculty in the structure
    design and training process of traditional convolutional networks. In this
    paper, we design a four-level convolutional network cascade, which tackles
    the problem in a coarse-to-ﬁne manner. In our system, each network level is
    trained to locally reﬁne a subset of facial landmarks generated by previous
    network levels. In addition, each level predicts explicit geometric
    constraints (the position and rotation angles of a speciﬁc facial component)
    to rectify the inputs of the current network level. The combination of
    coarse-to-ﬁne cascade and geometric reﬁnement enables our system to locate
    extensive facial landmarks (68 points) accurately in the 300-W facial
    landmark localization challenge.
  accessed:
    - year: 2022
      month: 5
      day: 4
  author:
    - family: Zhou
      given: Erjin
    - family: Fan
      given: Haoqiang
    - family: Cao
      given: Zhimin
    - family: Jiang
      given: Yuning
    - family: Yin
      given: Qi
  citation-key: zhouFanEtAl2013a
  container-title: 2013 IEEE International Conference on Computer Vision Workshops
  DOI: 10.1109/ICCVW.2013.58
  event: 2013 IEEE International Conference on Computer Vision Workshops (ICCVW)
  event-place: Sydney, Australia
  ISBN: 978-1-4799-3022-7
  issued:
    - year: 2013
      month: 12
  language: en
  page: 386-391
  publisher: IEEE
  publisher-place: Sydney, Australia
  source: DOI.org (Crossref)
  title: >-
    Extensive Facial Landmark Localization with Coarse-to-Fine Convolutional
    Network Cascade
  type: paper-conference
  URL: http://ieeexplore.ieee.org/document/6755923/

- id: zhuRaman2012a
  abstract: >-
    We present a unified model for face detection, pose estimation, and landmark
    estimation in real-world, cluttered images. Our model is based on a mixtures
    of trees with a shared pool of parts; we model every facial landmark as a
    part and use global mixtures to capture topological changes due to
    viewpoint. We show that tree-structured models are surprisingly effective at
    capturing global elastic deformation, while being easy to optimize unlike
    dense graph structures. We present extensive results on standard face
    benchmarks, as well as a new “in the wild” annotated dataset, that suggests
    our system advances the state-of-the-art, sometimes considerably, for all
    three tasks. Though our model is modestly trained with hundreds of faces, it
    compares favorably to commercial systems trained with billions of examples
    (such as Google Picasa and face.com).
  author:
    - family: Zhu
      given: Xiangxin
    - family: Ramanan
      given: Deva
  citation-key: zhuRaman2012a
  container-title: 2012 IEEE Conference on Computer Vision and Pattern Recognition
  DOI: 10.1109/CVPR.2012.6248014
  event: 2012 IEEE Conference on Computer Vision and Pattern Recognition
  ISSN: 1063-6919
  issued:
    - year: 2012
      month: 6
  page: 2879-2886
  source: IEEE Xplore
  title: Face detection, pose estimation, and landmark localization in the wild
  type: paper-conference

- id: zouShiEtAl2019a
  abstract: >-
    Object detection, as of one the most fundamental and challenging problems in
    computer vision, has received great attention in recent years. Its
    development in the past two decades can be regarded as an epitome of
    computer vision history. If we think of today's object detection as a
    technical aesthetics under the power of deep learning, then turning back the
    clock 20 years we would witness the wisdom of cold weapon era. This paper
    extensively reviews 400+ papers of object detection in the light of its
    technical evolution, spanning over a quarter-century's time (from the 1990s
    to 2019). A number of topics have been covered in this paper, including the
    milestone detectors in history, detection datasets, metrics, fundamental
    building blocks of the detection system, speed up techniques, and the recent
    state of the art detection methods. This paper also reviews some important
    detection applications, such as pedestrian detection, face detection, text
    detection, etc, and makes an in-deep analysis of their challenges as well as
    technical improvements in recent years.
  accessed:
    - year: 2021
      month: 11
      day: 24
  author:
    - family: Zou
      given: Zhengxia
    - family: Shi
      given: Zhenwei
    - family: Guo
      given: Yuhong
    - family: Ye
      given: Jieping
  citation-key: zouShiEtAl2019a
  container-title: arXiv:1905.05055 [cs]
  issued:
    - year: 2019
      month: 5
      day: 15
  source: arXiv.org
  title: 'Object Detection in 20 Years: A Survey'
  title-short: Object Detection in 20 Years
  type: article-journal
  URL: http://arxiv.org/abs/1905.05055
...
